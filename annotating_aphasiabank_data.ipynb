{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c43ad1c-2bd3-4d52-861e-79d94111d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114d87f-a46e-44b1-be18-d1c4d72cfa94",
   "metadata": {},
   "source": [
    "### Importing preprocessed file from preprocessing_aphasiabank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09dc951e-dfb6-4535-91db-59b0dae664cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"all_processed_files.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a10d6-ad98-4c33-94d4-814be07b60f1",
   "metadata": {},
   "source": [
    "### Annotating with general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f9e54c-af5f-4745-bc0f-3aac6adfd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4905\n"
     ]
    }
   ],
   "source": [
    "df = df_original[[\"Person\", \"Text\", \"mor\", \"gra\"]][:5000].copy()\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "\n",
    "def get_duration(sentence):\n",
    "    try:\n",
    "        return (re.search(\".+ \\\\x15(.+)\\\\x15\", sentence).group(1))\n",
    "    except AttributeError:\n",
    "         return \"NaN\"\n",
    "        \n",
    "def remove_time(sentence):\n",
    "    try:\n",
    "        return sentence.replace(re.search(\"\\\\x15.+\", sentence).group(0), \"\")\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "def duration_to_seconds(sentence):\n",
    "    try:\n",
    "        return float((int(re.search(\"_.+\", sentence).group(0)[1:]) - int(re.search(\".+_\", sentence).group(0)[:-1]))/1000)\n",
    "    except AttributeError:\n",
    "        return \"NaN\"\n",
    "    \n",
    "def assign_hesitation(text):\n",
    "    sentence = text\n",
    "    return (re.findall(\"(&-.+?) \", sentence))\n",
    "\n",
    "def return_clean_text(sentence, steps = False):\n",
    "    removed_gesture = re.sub(\"&=.+? \", \"\", str(sentence))#remove gestures first\n",
    "    removed_correction_marker = re.sub(\"\\[.+?\\] \", \"\", removed_gesture)\n",
    "    removed_hesitations = re.sub(\"&-\", \"\", removed_correction_marker)\n",
    "    only_words = re.sub(\"[^\\w ']\", \"\", removed_hesitations)# remove non-characters except for '\n",
    "    if steps == False:\n",
    "        #print(only_words)\n",
    "        return only_words\n",
    "    if steps == True:\n",
    "        #with f' you can't use \"\\n\"\n",
    "        print (\"0, Original sentence:\", sentence,\n",
    "                \"1, Removed gestures:\", removed_gesture,\n",
    "                \"2, Removed corrections:\", removed_correction_marker,\n",
    "                \"3, Removed hesitations:\", removed_hesitations,\n",
    "                \"4, Only words: \", only_words, sep=\"\\n\")\n",
    "        print(\"<------------------------------------------------------------------------------>\")\n",
    "        return only_words\n",
    "\n",
    "def retrieve_corrections(sentence):\n",
    "    corrections = []\n",
    "    first_layer = re.findall(\"(?<=\\s).+? \\[:.+?]\", sentence)\n",
    "    if len(first_layer) != 0:\n",
    "        for i in first_layer:\n",
    "            if re.search(\"\\[: (.+?)]\", i).group(1) == \"x@n\":\n",
    "                corrections.append(\"unintelligible\")\n",
    "            else:\n",
    "                second_layer = re.sub(\"\\[: \", \"\", i)\n",
    "                third_layer = re.sub(\"\\]\", \"\", second_layer)\n",
    "                fourth_layer = re.sub(\"<\", \"\", third_layer)\n",
    "                fifth_layer = re.sub(\"@u\", \"\", fourth_layer)\n",
    "                sixth_layer = fifth_layer.split()\n",
    "                corrections.append(tuple([sixth_layer[-2],sixth_layer[-1]]))\n",
    "    else:\n",
    "        corrections = \"NaN\"\n",
    "    return corrections\n",
    "\n",
    "df[\"hesitations\"] = df[\"Text\"].apply(lambda x: assign_hesitation(x))\n",
    "df[\"corrections\"] = df[\"Text\"].apply(lambda x: retrieve_corrections(x))\n",
    "df[\"duration\"] = df[\"Text\"].apply(lambda x: get_duration(x))\n",
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: remove_time(x))\n",
    "df[\"seconds\"] = df[\"duration\"].apply(lambda x: duration_to_seconds(x))\n",
    "df[\"Clean_text\"] = df[\"Text\"].apply(lambda x: return_clean_text(x, False))\n",
    "df[\"num_corrections\"] = df[\"corrections\"].apply(lambda x: len(x))\n",
    "df[\"num_unintelligible\"] = df[\"corrections\"].apply(lambda x: len([z for z in x if z == \"unintelligible\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07524be5-22b1-4ac8-9256-3863b3af2434",
   "metadata": {},
   "source": [
    "### Annotating with linguistic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "320f981c-dfbb-4c75-b2d3-14890fcf7731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"xcomp\"] = df[\"gra\"].apply(lambda x: 1 if \"XCOMP\" in x else 0)\n",
    "df[\"ccomp\"] = df[\"gra\"].apply(lambda x: 1 if \"COMP\" in x else 0)\n",
    "df[\"prepositional\"] = df[\"gra\"].apply(lambda x: 1 if \"LOC\" in x else 0)\n",
    "df[\"optional_elements\"] = df[\"gra\"].apply(lambda x: 1 if (\"JCT\" or \"CJCT\" or \"XJCT\") in x else 0)\n",
    "df[\"noun_modifiers\"] = df[\"gra\"].apply(lambda x: 1 if (\"MOD\" or \"CMOD\" or \"XMOD\") in x else 0)\n",
    "df[\"negation\"] = df[\"gra\"].apply(lambda x: 1 if \"NEG\" in x else 0)\n",
    "df[\"determiner\"] = df[\"gra\"].apply(lambda x: 1 if \"DET\" in x else 0)\n",
    "df[\"topicalization\"] = df[\"gra\"].apply(lambda x: 1 if \"TOP\" in x else 0)\n",
    "df[\"quantifier\"] = df[\"gra\"].apply(lambda x: 1 if \"QUANT\" in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f4060a-ad75-4af3-97f3-c9db90cb3bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person',\n",
       " 'Text',\n",
       " 'mor',\n",
       " 'gra',\n",
       " 'hesitations',\n",
       " 'corrections',\n",
       " 'duration',\n",
       " 'seconds',\n",
       " 'Clean_text',\n",
       " 'num_corrections',\n",
       " 'num_unintelligible',\n",
       " 'xcomp',\n",
       " 'ccomp',\n",
       " 'prepositional',\n",
       " 'optional_elements',\n",
       " 'noun_modifiers',\n",
       " 'negation',\n",
       " 'determiner',\n",
       " 'topicalization',\n",
       " 'quantifier']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501fabc-3a80-4d8e-82bd-6f62da6288b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
