{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66274733-a5a4-4c3a-94cb-7972a046279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb8028b-f0f1-471f-8f1a-03dd9b41c514",
   "metadata": {},
   "source": [
    "### Load data from AphasiaBank dataset found in the folder \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df45cc89-1945-4ba2-a25f-724383047bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "473\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset\"\n",
    "\n",
    "def get_file_names(path): #get all the file names from the path\n",
    "    all_names = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".cha\"):\n",
    "                all_names.append(os.path.join(root, file))\n",
    "                \n",
    "    return all_names\n",
    "\n",
    "f_names = get_file_names(path)\n",
    "print(len(f_names))\n",
    "f_names = [el for el in f_names if not 'checkpoint' in el] #remove \"checkpoint\" files, which are the duplicates of regular files\n",
    "print(len(f_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f5866-c385-482b-8c69-7860e786cd25",
   "metadata": {},
   "source": [
    "### Prepare dataframe from files with general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f2e0e6-52dc-40ae-8b94-697efec667be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file dataset\\ACWT\\ACWT\\ACWT01a.cha is empty\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Media</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11312/t-00017818-1</td>\n",
       "      <td>ACWT03a, video</td>\n",
       "      <td>eng|ACWT|PAR|68;01.|male|TransMotor||Participa...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11312/t-00017819-1</td>\n",
       "      <td>ACWT04a, video</td>\n",
       "      <td>eng|ACWT|PAR|26;00.|female|NotAphasicByWAB||Pa...</td>\n",
       "      <td>NotAphasicByWAB</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11312/t-00017820-1</td>\n",
       "      <td>ACWT05a, video</td>\n",
       "      <td>eng|ACWT|PAR|75;07.|male|Broca||Participant||5...</td>\n",
       "      <td>Broca</td>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11312/t-00017821-1</td>\n",
       "      <td>ACWT07a, video*INV:I'm gonna be asking you to ...</td>\n",
       "      <td>eng|ACWT|PAR|61;06.|male|NotAphasicByWAB||Part...</td>\n",
       "      <td>NotAphasicByWAB</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>11312/t-00018259-1</td>\n",
       "      <td>wright203a, video*INV:okay . \u00150_4506\u0015%mor:co|o...</td>\n",
       "      <td>eng|Wright|PAR|66;04.|male|Conduction||Partici...</td>\n",
       "      <td>Conduction</td>\n",
       "      <td>76.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>11312/t-00018260-1</td>\n",
       "      <td>wright204a, video*INV:www . \u00150_16008\u0015%exp:talk...</td>\n",
       "      <td>eng|Wright|PAR|74;10.|male|Anomic||Participant...</td>\n",
       "      <td>Anomic</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>11312/t-00018261-1</td>\n",
       "      <td>wright205a, video*INV:www . \u00150_5641\u0015%exp:extra...</td>\n",
       "      <td>eng|Wright|PAR|55;10.|male|Broca||Participant|...</td>\n",
       "      <td>Broca</td>\n",
       "      <td>59.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>11312/t-00018262-1</td>\n",
       "      <td>wright206a, video*INV:okay . \u00150_1533\u0015%mor:co|o...</td>\n",
       "      <td>eng|Wright|PAR|39;00.|female|Broca||Participan...</td>\n",
       "      <td>Broca</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>11312/t-00018263-1</td>\n",
       "      <td>wright207a, video*INV:www . \u00150_21089\u0015%exp:talk...</td>\n",
       "      <td>eng|Wright|PAR|63;10.|female|Broca||Participan...</td>\n",
       "      <td>Broca</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PID                                              Media  \\\n",
       "0    11312/t-00017817-1                                     ACWT02a, video   \n",
       "1    11312/t-00017818-1                                     ACWT03a, video   \n",
       "2    11312/t-00017819-1                                     ACWT04a, video   \n",
       "3    11312/t-00017820-1                                     ACWT05a, video   \n",
       "4    11312/t-00017821-1  ACWT07a, video*INV:I'm gonna be asking you to ...   \n",
       "..                  ...                                                ...   \n",
       "467  11312/t-00018259-1  wright203a, video*INV:okay . \u00150_4506\u0015%mor:co|o...   \n",
       "468  11312/t-00018260-1  wright204a, video*INV:www . \u00150_16008\u0015%exp:talk...   \n",
       "469  11312/t-00018261-1  wright205a, video*INV:www . \u00150_5641\u0015%exp:extra...   \n",
       "470  11312/t-00018262-1  wright206a, video*INV:okay . \u00150_1533\u0015%mor:co|o...   \n",
       "471  11312/t-00018263-1  wright207a, video*INV:www . \u00150_21089\u0015%exp:talk...   \n",
       "\n",
       "                                                    ID             Type  \\\n",
       "0    eng|ACWT|PAR|53;01.|female|TransMotor||Partici...       TransMotor   \n",
       "1    eng|ACWT|PAR|68;01.|male|TransMotor||Participa...       TransMotor   \n",
       "2    eng|ACWT|PAR|26;00.|female|NotAphasicByWAB||Pa...  NotAphasicByWAB   \n",
       "3    eng|ACWT|PAR|75;07.|male|Broca||Participant||5...            Broca   \n",
       "4    eng|ACWT|PAR|61;06.|male|NotAphasicByWAB||Part...  NotAphasicByWAB   \n",
       "..                                                 ...              ...   \n",
       "467  eng|Wright|PAR|66;04.|male|Conduction||Partici...       Conduction   \n",
       "468  eng|Wright|PAR|74;10.|male|Anomic||Participant...           Anomic   \n",
       "469  eng|Wright|PAR|55;10.|male|Broca||Participant|...            Broca   \n",
       "470  eng|Wright|PAR|39;00.|female|Broca||Participan...            Broca   \n",
       "471  eng|Wright|PAR|63;10.|female|Broca||Participan...            Broca   \n",
       "\n",
       "     Severity  \n",
       "0        74.6  \n",
       "1        69.3  \n",
       "2        96.0  \n",
       "3        57.7  \n",
       "4        95.0  \n",
       "..        ...  \n",
       "467      76.3  \n",
       "468      90.9  \n",
       "469      59.7  \n",
       "470      53.7  \n",
       "471      61.5  \n",
       "\n",
       "[472 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pid(text): #This is the ID of the actual interview\n",
    "    pid_start = text.index('@PID:') + 5\n",
    "    pid_end = pid_start + text[pid_start:].index('@')\n",
    "    pid = text[pid_start:pid_end].replace('\\n', '').replace('\\t', '')\n",
    "    return pid\n",
    "\n",
    "def get_media(text): #Abreviation of the institution conducting the experiment and the number of experiment + media type (text, sound, video)\n",
    "    media_start = text.index('@Media:') + 7\n",
    "    media_end = media_start + text[media_start:].index('@')\n",
    "    media = text[media_start:media_end].replace('\\n', '').replace('\\t', '')\n",
    "    return media\n",
    "\n",
    "def get_id_type_severity(text): #ID is a line with general information about the interview. Type is the aphasia type, and severity is the score for the aphasic person.\n",
    "    id_start = text.index('@ID:') + 4\n",
    "    id_end = id_start + text[id_start:].index('@')\n",
    "    ID = text[id_start:id_end].replace('\\n', '').replace('\\t', '')\n",
    "    if 'participant' not in ID.lower():  # the first ID is not of the participant\n",
    "        # search further\n",
    "        ID, aph_type, aph_severity = get_id_type_severity(text[id_end:])\n",
    "        return ID, aph_type, aph_severity\n",
    "    \n",
    "    splitted = ID.split('|')\n",
    "    aph_type = splitted[5]\n",
    "    aph_severity = splitted[9]\n",
    "    return ID, aph_type, aph_severity\n",
    "\n",
    "def get_dataset_w_filenames(f_names):\n",
    "    df = pd.DataFrame(columns=['PID', 'Media', 'ID', 'Type', 'Severity'])\n",
    "    \n",
    "    for f_name in f_names:\n",
    "        with open(f_name, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            \n",
    "        if not text:\n",
    "            print(f'file {f_name} is empty')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            general_pid = get_pid(text)\n",
    "            general_media = get_media(text)\n",
    "            id_, type_, severity = get_id_type_severity(text)\n",
    "        except:\n",
    "            print(f_name)\n",
    "            raise\n",
    "    \n",
    "        new_row = {'PID': general_pid, 'Media': general_media, 'ID': id_, \n",
    "                   'Type': type_ if type_ else np.nan, \n",
    "                   'Severity': float(severity) if severity else np.nan}\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_files = get_dataset_w_filenames(f_names)\n",
    "df_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962dc92a-159e-447e-a901-af74c8c85e14",
   "metadata": {},
   "source": [
    "### Prepare dataframe with all conversational information from all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ac6dd6-cb50-49f0-b791-010e327422fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Text</th>\n",
       "      <th>mor</th>\n",
       "      <th>gra</th>\n",
       "      <th>Task</th>\n",
       "      <th>PID</th>\n",
       "      <th>Media</th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*INV:</td>\n",
       "      <td>alright . \u00151200_2858\u0015</td>\n",
       "      <td>co|alright .</td>\n",
       "      <td>1|0|INCROOT 2|1|PUNCT</td>\n",
       "      <td>Speech</td>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*INV:</td>\n",
       "      <td>I'm going to be asking you to do some talking ...</td>\n",
       "      <td>pro:sub|I~aux|be&amp;1S part|go-PRESP inf|to aux|b...</td>\n",
       "      <td>1|3|SUBJ 2|3|AUX 3|0|ROOT 4|6|INF 5|6|AUX 6|3|...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*PAR:</td>\n",
       "      <td>okay . \u00156640_7205\u0015</td>\n",
       "      <td>co|okay .</td>\n",
       "      <td>1|0|INCROOT 2|1|PUNCT</td>\n",
       "      <td>Speech</td>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*INV:</td>\n",
       "      <td>tell me how you think your speech is these day...</td>\n",
       "      <td>v|tell pro:obj|me pro:int|how pro:per|you v|th...</td>\n",
       "      <td>1|0|ROOT 2|1|OBJ 3|5|LINK 4|5|SUBJ 5|1|COMP 6|...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*PAR:</td>\n",
       "      <td>good &amp;=nods &amp;-um not real good but good . [+ g...</td>\n",
       "      <td>adj|good neg|not adj|real adj|good conj|but ad...</td>\n",
       "      <td>1|0|INCROOT 2|1|NEG 3|4|MOD 4|1|JCT 5|1|CONJ 6...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>11312/t-00017817-1</td>\n",
       "      <td>ACWT02a, video</td>\n",
       "      <td>eng|ACWT|PAR|53;01.|female|TransMotor||Partici...</td>\n",
       "      <td>TransMotor</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person                                               Text  \\\n",
       "0  *INV:                              alright . \u00151200_2858\u0015   \n",
       "1  *INV:  I'm going to be asking you to do some talking ...   \n",
       "2  *PAR:                                 okay . \u00156640_7205\u0015   \n",
       "3  *INV:  tell me how you think your speech is these day...   \n",
       "4  *PAR:  good &=nods &-um not real good but good . [+ g...   \n",
       "\n",
       "                                                 mor  \\\n",
       "0                                       co|alright .   \n",
       "1  pro:sub|I~aux|be&1S part|go-PRESP inf|to aux|b...   \n",
       "2                                          co|okay .   \n",
       "3  v|tell pro:obj|me pro:int|how pro:per|you v|th...   \n",
       "4  adj|good neg|not adj|real adj|good conj|but ad...   \n",
       "\n",
       "                                                 gra    Task  \\\n",
       "0                              1|0|INCROOT 2|1|PUNCT  Speech   \n",
       "1  1|3|SUBJ 2|3|AUX 3|0|ROOT 4|6|INF 5|6|AUX 6|3|...  Speech   \n",
       "2                              1|0|INCROOT 2|1|PUNCT  Speech   \n",
       "3  1|0|ROOT 2|1|OBJ 3|5|LINK 4|5|SUBJ 5|1|COMP 6|...  Speech   \n",
       "4  1|0|INCROOT 2|1|NEG 3|4|MOD 4|1|JCT 5|1|CONJ 6...  Speech   \n",
       "\n",
       "                  PID           Media  \\\n",
       "0  11312/t-00017817-1  ACWT02a, video   \n",
       "1  11312/t-00017817-1  ACWT02a, video   \n",
       "2  11312/t-00017817-1  ACWT02a, video   \n",
       "3  11312/t-00017817-1  ACWT02a, video   \n",
       "4  11312/t-00017817-1  ACWT02a, video   \n",
       "\n",
       "                                                  ID        Type  Severity  \n",
       "0  eng|ACWT|PAR|53;01.|female|TransMotor||Partici...  TransMotor      74.6  \n",
       "1  eng|ACWT|PAR|53;01.|female|TransMotor||Partici...  TransMotor      74.6  \n",
       "2  eng|ACWT|PAR|53;01.|female|TransMotor||Partici...  TransMotor      74.6  \n",
       "3  eng|ACWT|PAR|53;01.|female|TransMotor||Partici...  TransMotor      74.6  \n",
       "4  eng|ACWT|PAR|53;01.|female|TransMotor||Partici...  TransMotor      74.6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_starters = set(['@UTF8', '@PID:', '@Begin', '@Languages:', '@Participants:', '@ID:',\n",
    "                    '@Date:', '@Media:', '@End', '@Window:'])\n",
    "\n",
    "not_needed_starters = set(['%gpx:', '%sit:', '%com:', '%exp:',\n",
    "                           '@Situation:', '@Transcriber:', '@Comment:']) | meta_starters\n",
    "\n",
    "people_starters = set(['*IN1:', '*IN2:', '*INV1:', '*INV2:', '*INV:', '*PAR:', '*PRT:', \n",
    "                       '*SP01:', '*ADU:', '*CAR:', '*OTH:'])\n",
    "\n",
    "task_starter = set(['@G:'])\n",
    "\n",
    "info_starters = set(['%gra:', '%mor:'])\n",
    "\n",
    "def get_starter(line):\n",
    "    try:\n",
    "        end_starter = line.index('\\t')\n",
    "    except:\n",
    "        try:\n",
    "            end_starter = line.index('\\n')\n",
    "        except:\n",
    "            end_starter = len(line)\n",
    "    return line[:end_starter]\n",
    "\n",
    "def get_dataset_with_contents(f_names, df_w_files_info):\n",
    "    overall_df = pd.DataFrame(columns=['Person', 'Text', 'mor', 'gra', 'Task', 'PID', 'Media', 'ID', 'Type', 'Severity'])\n",
    "\n",
    "    for f_name in f_names:\n",
    "        with open(f_name, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        this_file_df = pd.DataFrame(columns=['Person', 'Text', 'mor', 'gra', 'Task', 'PID', 'Media', 'ID', 'Type', 'Severity'])\n",
    "\n",
    "        general_pid = get_pid(text)\n",
    "        file_info_line = df_w_files_info[df_w_files_info.PID == general_pid]\n",
    "        general_media, id_ = file_info_line.Media.values[0], file_info_line.ID.values[0]\n",
    "        type_, severity = file_info_line.Type.values[0], file_info_line.Severity.values[0]\n",
    "\n",
    "        try:\n",
    "            text_split = text.split('\\n')\n",
    "            persons = []\n",
    "            texts = []\n",
    "            mors = []\n",
    "            gras = []\n",
    "            tasks = []\n",
    "\n",
    "            for j, line in enumerate(text_split):\n",
    "\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if not line.startswith('\\t'):\n",
    "                    starter = get_starter(line)\n",
    "\n",
    "                    if starter in not_needed_starters:\n",
    "                        # check if mor and gra have the same number of elements as persons\n",
    "                        # if not -- it means that the previous one didn't have mor or gra\n",
    "                        # so we'll add empty lines there\n",
    "                        if len(persons) == (len(mors) + 1):\n",
    "                            mors.append('')\n",
    "                        if len(persons) == (len(gras) + 1):\n",
    "                            gras.append('')\n",
    "                        continue\n",
    "\n",
    "                    elif starter in people_starters:\n",
    "                        # check if mor and gra have the same number of elements as persons\n",
    "                        # if not -- it means that the previous one didn't have mor or gra\n",
    "                        # so we'll add empty lines there\n",
    "                        if len(persons) == (len(mors) + 1):\n",
    "                            mors.append('')\n",
    "                        if len(persons) == (len(gras) + 1):\n",
    "                            gras.append('')\n",
    "\n",
    "                        # check if 'tasks' have the same length as persons\n",
    "                        # it means that we need to add the same task again \n",
    "                        # to account for the newly added person\n",
    "                        # but if they are both 0 then we haven't seen the task yet, and we should add '' in tasks\n",
    "                        if (len(tasks) == 0) and (len(persons) == 0):\n",
    "                            tasks.append('')\n",
    "                        elif len(tasks) == len(persons):\n",
    "                            tasks.append(tasks[-1])\n",
    "                        elif len(tasks) == len(persons) + 1:\n",
    "                            pass  # that's ok, another person will be added right away\n",
    "                        else:\n",
    "                            raise ValueError('The number of tasks is more than the numner of persons by 2')\n",
    "\n",
    "                        persons.append(starter)\n",
    "                        texts.append(line[len(starter)+1:])\n",
    "                        continue\n",
    "\n",
    "                    elif starter in info_starters:\n",
    "                        if starter == '%mor:':\n",
    "                            mors.append(line[len(starter)+1:])\n",
    "                        elif starter == '%gra:':\n",
    "                            gras.append(line[len(starter)+1:])\n",
    "                        else:\n",
    "                            raise ValueError('Not recognized info starter')\n",
    "\n",
    "                    elif starter in task_starter:\n",
    "                        # it can be either before or after the first interviewer\n",
    "                        # but we deal with it while adding persons \n",
    "                        tasks.append(line[len(starter)+1:])\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print('-', starter, '-', sep='')\n",
    "                        print(line, j)\n",
    "                        raise ValueError('Starter not in the sets')\n",
    "\n",
    "                else:  # line starts with \\t so it's continuation of the previous one\n",
    "                    # attach it to the previous tag\n",
    "                    # 'starter' still has this!\n",
    "                    if starter in people_starters:\n",
    "                        texts[-1] = texts[-1] + line.lstrip('\\t')\n",
    "                    elif starter in info_starters:\n",
    "                        if starter == '%mor:':\n",
    "                            mors[-1] = mors[-1] + line.lstrip('\\t')\n",
    "                        else:\n",
    "                            gras[-1] = gras[-1] + line.lstrip('\\t')\n",
    "                    elif starter in not_needed_starters:  # line starts with \\t but previous one was not taken\n",
    "                        continue  # we don't take this either\n",
    "                    else:\n",
    "                        raise ValueError('strange previous starter')\n",
    "\n",
    "            assert len(persons) == len(texts), print(len(persons), len(texts))\n",
    "            assert len(texts) == len(mors), print(len(texts), len(mors))\n",
    "            assert len(mors) == len(gras), print(len(mors), len(gras))\n",
    "            assert len(gras) == len(tasks), print(len(gras), len(tasks))\n",
    "\n",
    "        except:\n",
    "            print(f_name)\n",
    "            raise\n",
    "\n",
    "        this_file_df['Person'] = persons\n",
    "        this_file_df['Text'] = texts\n",
    "        this_file_df['mor'] = mors\n",
    "        this_file_df['gra'] = gras\n",
    "        this_file_df['Task'] = tasks\n",
    "        this_file_df['PID'] = [general_pid] * len(persons)\n",
    "        this_file_df['Media'] = [general_media] * len(persons)\n",
    "        this_file_df['ID'] = [id_] * len(persons)\n",
    "        this_file_df['Type'] = [type_ if type_ else np.nan] * len(persons)\n",
    "        this_file_df['Severity'] = [float(severity) if severity else np.nan] * len(persons)\n",
    "\n",
    "        overall_df = pd.concat((overall_df, this_file_df))\n",
    "\n",
    "    return overall_df\n",
    "\n",
    "df_with_contents = get_dataset_with_contents(f_names, df_files)\n",
    "df_with_contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70d037-4f0b-48fb-8253-73418c329b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
